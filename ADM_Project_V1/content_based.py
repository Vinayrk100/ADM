# -*- coding: utf-8 -*-
"""test_content_based_book.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FMx2cdM-M1NQvBWwaKhmHf5Qdy-a5Auk
"""

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import re
import sklearn.metrics.pairwise as pw
from scipy import sparse
from sklearn.metrics.pairwise import pairwise_distances
from ast import literal_eval

books_details_df = pd.read_csv('C:/Users/Nikhita/Desktop/Dataset/Final/sample_data.csv')

# Convert the stringified objects into the native python objects

books_details_df['authors'] = books_details_df['book_authors'].fillna('')
# books_details_df['language_code'] = books_details_df['language_code'].fillna('')
books_details_df['genres'] = books_details_df['genres'].fillna('')

# books_details_df['authors']

def sanitize(x):
    if isinstance(x, list):
        #Strip spaces and convert to lowercase
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        #Check if director exists. If not, return empty string
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
            return ''

#Apply the generate_list function to cast, keywords, director and genres
for feature in ['book_authors', 'language_code']:
    books_details_df[feature] = books_details_df[feature].apply(sanitize)

books_details_df['soup'] = books_details_df['book_authors'] + books_details_df['genres']
# books_details_df['soup'] = books_details_df['authors']

#Display the soup of the first movie
books_details_df.iloc[0]['soup']

# Import CountVectorizer
from sklearn.feature_extraction.text import CountVectorizer

# Define a new CountVectorizer object and create vectors for the soup
count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(books_details_df['soup'])
# count_matrix1 = count.fit_transform(books_details_df[['authors','original_publication_year']])

count_matrix

# Import cosine_similarity function
from sklearn.metrics.pairwise import cosine_similarity

# Compute the cosine similarity score (equivalent to dot product for tf-idf vectors)
cosine_sim2 = cosine_similarity(count_matrix, count_matrix)

# Reset index of your df and construct reverse mapping again
books_details_df = books_details_df.reset_index()
indices2 = pd.Series(books_details_df.index, index=books_details_df['title'])

cosine_sim2 = 1-pairwise_distances(count_matrix, metric="cosine")

books_details_df.head()

cosine_sim2

# sparse_pivot = sparse.csr_matri
# x(cosine_sim2.fillna(cosine_sim2.mean(axis=0)))



indices2

# Function that takes in movie title as input and gives recommendations
def content_recommender(title, cosine_sim=cosine_sim2, df=books_details_df, indices=indices2):
    # Obtain the index of the movie that matches the title
    idx = indices2[title]

    # Get the pairwsie similarity scores of all movies with that movie
    # And convert it into a list of tuples as described above
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort the movies based on the cosine similarity scores
    # sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sorted(sim_scores, reverse=True)
    # Get the scores of the 10 most similar movies. Ignore the first movie.
    sim_scores = sim_scores[1:11]

    # Get the movie indices
    movie_indices = [i[0] for i in sim_scores]

    # Return the top 10 most similar movies
    return df['title'].iloc[movie_indices]

a = content_recommender('Saga, Vol. 2 (Saga, #2)', cosine_sim2, books_details_df, indices2)

print(a)